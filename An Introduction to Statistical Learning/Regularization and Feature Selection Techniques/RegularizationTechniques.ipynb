{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RegularizationTechniques","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1C2ixli3at5AdRsHVTCCypNxd0cXT_X-2","authorship_tag":"ABX9TyNAJiUqwxtXQbvWGkrWhkIT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"m7RfcQAv_-fx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593171407380,"user_tz":-330,"elapsed":1615,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"f59a4160-f54d-4f37-93c4-6486a2aef1f9"},"source":["import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from matplotlib import style\n","\n","style.use('fivethirtyeight')\n","%matplotlib inline"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"n0uQQgsDaPAS","colab_type":"code","colab":{}},"source":["data = pd.read_csv('/content/drive/My Drive/Repos/Git/Machine-Learning/An Introduction to Statistical Learning/Dataset/Auto.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9D4v1ygqaQV8","colab_type":"code","colab":{}},"source":["data.horsepower.replace('?',np.NaN,inplace=True)\n","data.dropna(inplace=True)\n","data.horsepower = pd.to_numeric(data.horsepower)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3eY5EJwUac17","colab_type":"code","colab":{}},"source":["X = data[['cylinders','displacement','horsepower','weight','acceleration']]\n","y = data.mpg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UEczw6k-2uqv","colab_type":"text"},"source":["# **Regularization**"]},{"cell_type":"markdown","metadata":{"id":"D2p3izvB9IZN","colab_type":"text"},"source":["## **What is Regularization?**\n","\n","**Regularization** is a technique to discourage the complexity of the model. It does by penalizing the loss function. This helps us solve the overfitting problem.\n","\n","**Loss Function** is the sum of square between the actual value and the predicted value.\n","\n","<center>$L(x,y) = \\overset{n}{\\underset{i=1}{\\sum}}(y_i-f(x_i))^2$</center>\n","<center>$f(x_i) = h_\\theta xf(x_i) = h_\\theta x = \\theta_0+\\theta_1x_1+\\theta_2x_2^2+\\theta_3x_3^3+\\theta_4x_4^4$</center>\n","\n","As the degree of the input features the complexity of the model increases and it tries to fit all the data points.\n","\n","An Example:\n","\n","![alt text](https://drive.google.com/uc?export=view&id=1VGP9VyWgVHsq94qMGHsR5YSySs1M6PS-)\n","\n","Regularization works on the assumption that smaller weights generate a simpler model and thus help avoid overfitting. Hence, we penalize the weights $\\theta_3$ and $\\theta_4$ and make them too small, very close to zero to simplify the model.\n","\n","<center>$f(x_i) = h_\\theta x = \\theta_0+\\theta_1x_1+\\theta_2x_2^2$</center>\n","\n","To ensure we take all the input variables into account, we penalize all the weights by making them small. This also makes the model simpler and less prone to **overfitting**.\n","\n","<center>$L(x,y) = \\overset{n}{\\underset{i=1}{\\sum}(y_i-f(x_i))^2 +\\lambda\\overset{n}{\\underset{i=1}{\\sum}}\\theta_i^2}$</center>\n","\n","We have added the **regularization** term to the **Loss Function**. The Regularization term keeps the weight small by making the model simple and avoid overfitting.\n","\n","$\\lambda$ is the penalty term or regularization parameter which determines how much to penalize the weights."]},{"cell_type":"markdown","metadata":{"id":"KCAth0SuGWg0","colab_type":"text"},"source":["## **L1 Regularization or Lasso or L1 norm**\n","\n","In L1 Regularization we shrink the parameters to zero. When the input features have weights closer to zero that leads to sparse L1 Regression. In sparse solution majority of the input features have zero weights and very few features have non zero weights.\n","\n","<center>$L(x,y) = \\overset{n}{\\underset{i=1}{\\sum}}(y_i-f(x_i))^2+\\lambda\\overset{n}{\\underset{i=1}{\\sum}}|\\theta_i|$</center>\n","\n","In L1 Regression, we penalize the absolute value of the weights. Lasso produces a model that is simple, interpretable and contains a subset of input features."]},{"cell_type":"code","metadata":{"id":"cFdGGUZoKRBr","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_log_error,r2_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdDsyWtuLeOb","colab_type":"code","colab":{}},"source":["lr = LinearRegression()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Wgfx72dLhsO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"ok","timestamp":1593171407387,"user_tz":-330,"elapsed":1585,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"a64f67ba-72e2-4525-eb06-630328250383"},"source":["X = X.values.reshape(-1,5)\n","X"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   8. ,  307. ,  130. , 3504. ,   12. ],\n","       [   8. ,  350. ,  165. , 3693. ,   11.5],\n","       [   8. ,  318. ,  150. , 3436. ,   11. ],\n","       ...,\n","       [   4. ,  135. ,   84. , 2295. ,   11.6],\n","       [   4. ,  120. ,   79. , 2625. ,   18.6],\n","       [   4. ,  119. ,   82. , 2720. ,   19.4]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"qH1jI0EqMlFP","colab_type":"code","colab":{}},"source":["X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsTcWSh2LtzO","colab_type":"code","colab":{}},"source":["model = lr.fit(X_train,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"alnv64e3NIkC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593171407389,"user_tz":-330,"elapsed":1567,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"bac6b83d-4b21-4c9c-d57e-0ec021b5764a"},"source":["r2_score(y_test,model.predict(X_test))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7494076237091598"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"tgUG8N8xM33J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593171407390,"user_tz":-330,"elapsed":1559,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"65f9d52f-d63f-4b9c-86fc-1de71b1abc59"},"source":["mean_squared_log_error(y_test,model.predict(X_test))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.027159419844415323"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"JoA9vuQXL3Rs","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import Lasso\n","from sklearn.model_selection import GridSearchCV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4T5zrcb7MJEG","colab_type":"code","colab":{}},"source":["reg_lr = Lasso(fit_intercept=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0PPyKbOMXSo","colab_type":"code","colab":{}},"source":["param_grid = {'alpha':np.arange(0,1,0.001)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MD-j-KRQNply","colab_type":"code","colab":{}},"source":["from sklearn.metrics import SCORERS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJnp7rUwNyy9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1593171407394,"user_tz":-330,"elapsed":1534,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"a65803fd-6357-472b-903e-169c18af3f19"},"source":["SCORERS.keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"NrlS33fyNT-U","colab_type":"code","colab":{}},"source":["# for finding the best alpha value.\n","cross_validation = GridSearchCV(estimator=reg_lr,param_grid=param_grid,scoring='r2',cv=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1GXpUTSdOG5V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":882},"executionInfo":{"status":"ok","timestamp":1593171416147,"user_tz":-330,"elapsed":10272,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"eac7d014-2b9e-4e44-e7cb-501451ffd994"},"source":["cross_validation.fit(X_train,y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2386.3415123930445, tolerance: 1.5179595240000001\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2376.5524269026623, tolerance: 1.5703736959999997\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2149.8096720153144, tolerance: 1.4371913440000001\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2154.654711998496, tolerance: 1.455233227091633\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2406.4161645056333, tolerance: 1.5845186374501992\n","  positive)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, error_score=nan,\n","             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n","                             max_iter=1000, normalize=False, positive=False,\n","                             precompute=False, random_state=None,\n","                             selection='cyclic', tol=0.0001, warm_start=False),\n","             iid='deprecated', n_jobs=None,\n","             param_grid={'alpha': array([0.   , 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n","       0.009, 0.01 , 0.011, 0.012, 0...\n","       0.954, 0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962,\n","       0.963, 0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971,\n","       0.972, 0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 ,\n","       0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989,\n","       0.99 , 0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998,\n","       0.999])},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring='r2', verbose=0)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"E4hAKtbnONv3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593171416151,"user_tz":-330,"elapsed":10266,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"155dfc0f-8635-4dfe-9fba-bc7a485d056c"},"source":["cross_validation.best_score_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6835081660272463"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"IH7RMKMMOWOl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593171416154,"user_tz":-330,"elapsed":10258,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"3b41b917-514a-46b5-ca4b-0c23e7f3c4b0"},"source":["cross_validation.best_params_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'alpha': 0.666}"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"2quuieOZOZZO","colab_type":"code","colab":{}},"source":["lasso = cross_validation.best_estimator_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EcmiX72BOpZZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593171416156,"user_tz":-330,"elapsed":10245,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"5b4c7fd5-4eae-441d-f59b-4bf76587b360"},"source":["r2_score(y_test,lasso.predict(X_test))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7506243780485066"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"oLlTYnj6Pqt2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593171416158,"user_tz":-330,"elapsed":10239,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"b52d2c2f-a433-476d-b3e9-7cfca055da7d"},"source":["model.coef_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.47432468,  0.0038803 , -0.05381485, -0.00524477, -0.03547731])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"jOk-gomuPtkt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593171416159,"user_tz":-330,"elapsed":10233,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"a74d1488-9ac4-409e-a3f6-8ed2f977a0b1"},"source":["lasso.coef_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.        , -0.00323215, -0.0476521 , -0.00546493, -0.        ])"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"GL_SjXvJP-hS","colab_type":"text"},"source":["as we can see comparing both the coefficients, the lasso models are closer to zero."]},{"cell_type":"markdown","metadata":{"id":"77H0mrtyG99u","colab_type":"text"},"source":["## **L2 Regularization or Ridge Regularization**\n","\n","In L2 Regularization, the regularization term is the sum of the squares of all the feature weights. It forces the weights to be small but does not make them to be zero and does non sparse solution.\n","\n","<center>$L(x,y) = \\overset{n}{\\underset{i=1}{\\sum}}(y_i-f(x_i))^2+\\lambda\\overset{n}{\\underset{i=1}{\\sum}}\\theta_i^2$</center>\n","\n","L2 is not robust to outliers as square terms blows up the error differences and the regularization term tries to fix it by penalizing the weights.\n","\n","Ridge regression performs better when all the input features are influenced by the output and all the weights are roughly equal size."]},{"cell_type":"code","metadata":{"id":"aDo9pPLxQGy-","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import Ridge"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gSRBWnzaQSVq","colab_type":"code","colab":{}},"source":["r = Ridge(fit_intercept=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0oSb1SIQOXz","colab_type":"code","colab":{}},"source":["cross_validation = GridSearchCV(r,param_grid,scoring='r2',cv=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11Y1MwtMQg9P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"status":"ok","timestamp":1593171424240,"user_tz":-330,"elapsed":18293,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"5a50c6c4-8fac-486d-c960-154f2027765c"},"source":["cross_validation.fit(X_train,y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, error_score=nan,\n","             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n","                             max_iter=None, normalize=False, random_state=None,\n","                             solver='auto', tol=0.001),\n","             iid='deprecated', n_jobs=None,\n","             param_grid={'alpha': array([0.   , 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n","       0.009, 0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017,\n","       0.018, 0.019, 0.02 , 0.021, 0.0...\n","       0.954, 0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962,\n","       0.963, 0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971,\n","       0.972, 0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 ,\n","       0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989,\n","       0.99 , 0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998,\n","       0.999])},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring='r2', verbose=0)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"c96G7bsgQjwH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593171424241,"user_tz":-330,"elapsed":18284,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"5710e057-834d-4fb5-f29a-2a14f6da9879"},"source":["cross_validation.best_params_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'alpha': 0.999}"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"xV1SyozXQqcK","colab_type":"code","colab":{}},"source":["ridge = cross_validation.best_estimator_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JVoNZFJQ0CO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593171424247,"user_tz":-330,"elapsed":18278,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"02fac7bb-88bf-431d-aa3b-b4e07bdc4ac4"},"source":["r2_score(y_test,ridge.predict(X_test))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7494275630823424"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"SJTNdOz5bOzV","colab_type":"text"},"source":["## **Elastic Net**\n","\n","Elastic Net combines characteristics of both lasso and ridge. It reduces the impact of different features while not eliminating all the features.\n","\n","The formula as you can see below is the sum of lasso and ridge formulas.\n","\n","***Elastic Net Formula***\n","\n","<center>$L(x,y) = \\overset{n}{\\underset{i=1}{\\sum}}(y_i-f(x_i))^2+\\lambda\\overset{n}{\\underset{i=1}{\\sum}}\\theta_i^2+\\lambda\\overset{n}{\\underset{i=1}{\\sum}}|\\theta_i|$</center>\n","\n","- To conclude, Lasso, Ridge and Elastic Net are excellent methods to improve the performance of Linear Model.\n","\n","- This includes if you are also running a neural network, a collection of linear models.\n","\n","- Lasso will eliminate many features and reduce overfitting in your linear model.\n","\n","- Ridge will reduce the impact of features that are not important in predicting $y$ values.\n","\n","-  Elastic net combines feature elimination from Lasso and feature coefficient reduction from Ridge model to improve you'r models predictions."]},{"cell_type":"code","metadata":{"id":"6oRk-E46eVKt","colab_type":"code","colab":{}},"source":["from sklearn.datasets import make_regression\n","from sklearn.linear_model import ElasticNet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sagZ0QEheb5c","colab_type":"code","colab":{}},"source":["X,y = make_regression(n_features=15,n_informative=10,random_state=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-7PeHyRfgTZ","colab_type":"code","colab":{}},"source":["X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFNzWMbvf76c","colab_type":"code","colab":{}},"source":["en = ElasticNet(fit_intercept=True)\n","param_grid={'alpha':np.arange(0,1.01,0.01)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tO9BLDu5h_fV","colab_type":"code","colab":{}},"source":["cross_validation = GridSearchCV(en,param_grid,scoring='r2',cv=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ArzxLKciKIn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":790},"executionInfo":{"status":"ok","timestamp":1593173400034,"user_tz":-330,"elapsed":1444,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"d5b145a5-5862-47d9-82b8-5e0f75c0a103"},"source":["cross_validation.fit(X_train,y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:515: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  estimator.fit(X_train, y_train, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:739: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  self.best_estimator_.fit(X, y, **fit_params)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  positive)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, error_score=nan,\n","             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n","                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n","                                  positive=False, precompute=False,\n","                                  random_state=None, selection='cyclic',\n","                                  tol=0.0001, warm_start=False),\n","             iid='deprecated', n_jobs=None,\n","             param_grid={'alpha': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n","       0.11,...\n","       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n","       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n","       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n","       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n","       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n","       0.99, 1.  ])},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring='r2', verbose=0)"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"ttVsjva0iNPi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593173415935,"user_tz":-330,"elapsed":846,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"968852fa-006f-4308-e5e6-b91a5271ffa5"},"source":["cross_validation.best_params_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'alpha': 0.0}"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"o8G7XwDWiRQ5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1593173450067,"user_tz":-330,"elapsed":810,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"44751536-db8f-4be9-d021-31ef02ce1411"},"source":["cross_validation.best_estimator_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ElasticNet(alpha=0.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n","           max_iter=1000, normalize=False, positive=False, precompute=False,\n","           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"RwR_r7eDiZnM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593173468352,"user_tz":-330,"elapsed":944,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"6181be36-eed5-4ac2-ecbf-8baab818cfcc"},"source":["cross_validation.best_score_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9999999968724677"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"fKXedTEBiuWK","colab_type":"code","colab":{}},"source":["elastic_net = cross_validation.best_estimator_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTPdf6UUid4_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593173567797,"user_tz":-330,"elapsed":1835,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"8381264a-b278-4ece-db81-a92bd5b45ea1"},"source":["r2_score(y_test,elastic_net.predict(X_test))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9999999980887385"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"LrP75PBYiinS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1593173588955,"user_tz":-330,"elapsed":1116,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}},"outputId":"0d4e2f31-22d9-46b9-bb28-f8f16e83a46f"},"source":["elastic_net.coef_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 3.54687290e+01,  8.26319782e+01,  6.61331368e-04,  3.17512885e-03,\n","        2.51570147e+01,  6.47970302e+01,  6.98212315e+01,  5.47048989e-04,\n","        5.45103963e+01, -1.69987747e-03,  6.16328994e+01,  4.68878982e+01,\n","       -3.20707479e-04,  4.06480766e+01,  5.01764030e+01])"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"GdHmFYPTi7UQ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}