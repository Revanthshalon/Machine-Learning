{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Feature Selection Techniques.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1fjw2g3cf56lZkky_RFCb_suR8qOvACwt","authorship_tag":"ABX9TyOfVZ3E3fOr2WHg4FK18alw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AY6p61Tqj83Q","colab_type":"text"},"source":["# Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"G4oN6_bqkMlc","colab_type":"text"},"source":["**What is Feature Selection and its uses?**\n","- Feature selection is one of the core concepts in machine learning, which hugely impacts the performance of a model.\n","- The data features that we use to train your machine learning models have a huge influence on the performance that we can achive.\n","- Irrelavant or partially relevant features can negatively impact the model.\n","- Feature selection and Data cleaning is one of the most important steps in model designing.\n"]},{"cell_type":"markdown","metadata":{"id":"5jZnFv5Zlfzq","colab_type":"text"},"source":["**Benefits of Feature Selection:**\n","- Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n","- Improves Accuracy: Less misleading data means model accuracy improvse.\n","- Reduces Training time: Less data means algorithm train faster."]},{"cell_type":"markdown","metadata":{"id":"9MAoao7dl-RD","colab_type":"text"},"source":["**Types of Features Selection algorithms:**\n","- There are two main types of Feature Selection Algorithms.\n","  - Wrapper Feature Selection Methods.\n","  - Filter Feature Selection Methods.\n","  "]},{"cell_type":"markdown","metadata":{"id":"8zQB_itFnkUl","colab_type":"text"},"source":["# Wrapper Feature Selection Methods"]},{"cell_type":"markdown","metadata":{"id":"Kk7PgLZQnok8","colab_type":"text"},"source":["**What is meant by Wrapper Feature Selection?**\n","- It creates many models, with different subset of input features and select those features that result in best performing model according to a performance metric.\n","- These methods are unconcerned about the variable types, although they can be computationally expensive.\n","- **Recursive Feature Elimination(RFE)** is a good example of wrapper feature selection method.\n","\n","***Definition:***\n","- *Wrapper methods evaluvate multiple models using procedures that add/or remove predictors to find the optimal combination that maximizes the model performance.*"]},{"cell_type":"markdown","metadata":{"id":"RTUm8u16o26t","colab_type":"text"},"source":["# Filter Feature Selection Methods"]},{"cell_type":"markdown","metadata":{"id":"VvyKTAizo7WT","colab_type":"text"},"source":["**What is meant by Filter Feature Selection?**\n","- Filter Features Selection uses statistical techniques to evaluvate the relationship between each predictor and the response variable and these scores are used as a basis to choose(filter) those predictors that can be used in your model.\n","\n","**Definition:**\n","- *Filter methods evaluvate the relevance of the predictors outside the predictive models and subsequently model only the predictors that pass some criterion*\n","\n","**Application of Filter Feature Selection:**\n","- It is common to use correlation type statistical measures between input and output variables as a basis for Filter Feature Selection.\n","- As such the choice of statistical measure is highly dependant upon the variable or predictor data types.\n","- Common datatype include both quantitative and qualitative although it may subdivide such as integer and floating point in quantitative and boolean, ordinal or nominal in qualitative predictors.\n","- Common input predictor datatypes:\n","  - Quantitative Predictors.\n","    - Integer Variables\n","    - Floating Point Varaibles\n","  - Qualitative Predictors.\n","    - Boolean Variables(dichotomos)\n","    - Ordinal Variables\n","    - Nominal Varaibles"]},{"cell_type":"markdown","metadata":{"id":"7EGCG-workX3","colab_type":"text"},"source":["## Statistics for Filter based Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"5ZHPHcwwtzrn","colab_type":"text"},"source":["- There are two main groups of variables to consider are : predictors and response variables.\n","- Predictors are the input variables. These are the variables that we wish to reduce in size\n","- Response variable are the output variables, which the model is intended to predict.\n","- The type of response variable  typically indicates the type of predictive modelling problem being performed.\n","  - Numerical Output: Regression predictive modelling problem.\n","  - Categorical Output: Classification predictive modellig problem.\n","- Statistical Measures used in Filter Feature Selection are generally calculated one input variable at a time with the response variable.These are reffered to as the univariate statistical measures."]},{"cell_type":"markdown","metadata":{"id":"bni8AeAxvXyz","colab_type":"text"},"source":["$\\text{Input Features}\\rightarrow\\begin{cases}\n","\\text{Numerical Features}\\rightarrow\\text{Output Variable}\n","\\begin{cases}\n","\\text{Numerical}\\begin{cases}\n","\\text{Pearson's}\\\\\n","\\text{Spearman's}\n","\\end{cases}\\\\\n","\\text{Categorical}\\begin{cases}\n","\\text{ANOVA}\\\\\n","\\text{Kendall's}\n","\\end{cases}\n","\\end{cases}\\\\\n","\\text{Categorical Features}\\rightarrow\\text{Output Variable}\\begin{cases}\n","\\text{Numerical}\\begin{cases}\n","\\text{ANOVA}\\\\\n","\\text{Kendall's}\n","\\end{cases}\\\\\n","\\text{Categorical}\\begin{cases}\n","\\text{Chi-Squared}\\\\\n","\\text{Mutual Information}\n","\\end{cases}\n","\\end{cases}\n","\\end{cases}$"]},{"cell_type":"markdown","metadata":{"id":"WCVxFdCBxE3l","colab_type":"text"},"source":["## Numerical Input, Numerical Output"]},{"cell_type":"markdown","metadata":{"id":"WH7pzC6tRD63","colab_type":"text"},"source":["- This is a regression predictive modeling problem with numerical input variables.\n","- The most common techniques are to usea correlation coefficient, such as Pearsons's for a linear correlation, or rank-based methods for a non linear correlation.\n","  - Pearson's Correlation Coefficient (Linear)\n","  - Spearman's Rank Coeffiecient (Non Linear)"]},{"cell_type":"markdown","metadata":{"id":"oiuSE80tRw5L","colab_type":"text"},"source":["## Numerical Input, Categorical Output"]},{"cell_type":"markdown","metadata":{"id":"-FMmnJb8R0Tk","colab_type":"text"},"source":["- This is a classification predictive modeling problem with numerical input problems.\n","- This might be common example of a common regression problem.\n","- Again, the most common techniques are correlation based, although this is the case, they must take categorical target into account.\n","  - ANOVA correlation coefficient (Linear)(ANalysis Of VAriance)\n","  - Kendall's rank coeffiencient (Non Linear)\n","- Kendall does assume that the categorical variables are ordinal."]},{"cell_type":"markdown","metadata":{"id":"9wx7i6ooS-G5","colab_type":"text"},"source":["## Categorical Input, Numerical Output"]},{"cell_type":"markdown","metadata":{"id":"8cYzUTQgTEcc","colab_type":"text"},"source":["- This is a regression predictive modeling with categorical input variables.\n","- This is a strange example of regression problem.\n","- Neverthless, you can use the same \"Numerical Input, Categorical Output\" methods, but in reverse."]},{"cell_type":"markdown","metadata":{"id":"xxmcXpj8TlPc","colab_type":"text"},"source":["## Catergorical Input, Categorical Output"]},{"cell_type":"markdown","metadata":{"id":"QUW-G3N3To5z","colab_type":"text"},"source":["- This is a Classification Predictive Modeling Problem with categorical input variable.\n","- The most common correaltion measure for categorical data the chi-squared test. We can also use the mutual information(information gain) from the field of information theory.\n","  - Chi-Squared test(contigency tables)\n","  - Mutual information\n","- Mutual information is a powerful method that may prove useful for both numerical and categorical data, e.g,it is agnostic to datatypes."]},{"cell_type":"markdown","metadata":{"id":"3S-XVlsjUtgr","colab_type":"text"},"source":["# Tips and Tricks for Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"tXV9TPUXUxwa","colab_type":"text"},"source":["## Correlation Statistics"]},{"cell_type":"markdown","metadata":{"id":"S_8nSIdhU39R","colab_type":"text"},"source":["- The scikit-learn library provides an implementation of some of the most useful statistical measures.\n","- For example:\n","  - Pearson's correlation coefficient: [f_regression()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html)\n","  - ANOVA: [f_classif()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html)\n","  - Chi-Squares: [chi2()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html)\n","  - Mutual Information: [mutual_info_classif()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html) and [mutual_info_regression()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html)\n","- Also the SciPy Library provides an implementation of Kendall's tau([kendalltau](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html)) and Spearman's rank Correlation([spreamanr](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html))"]},{"cell_type":"markdown","metadata":{"id":"kaJqNs-2WNln","colab_type":"text"},"source":["## Selection Method"]},{"cell_type":"markdown","metadata":{"id":"y61BQKrxWzRr","colab_type":"text"},"source":["- The scikit-learn library also provides many different filtering methods once statistics have been calculated for each input predictor with the response.\n","- The Two most popular methods include,\n","  - select top K predictors: [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)\n","  - Select the top percentil Predictors: [SelectPercentile](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html)"]},{"cell_type":"markdown","metadata":{"id":"7EOIwmEBXeDX","colab_type":"text"},"source":["## Transforming Predictors"]},{"cell_type":"markdown","metadata":{"id":"XpniyxDPXiMb","colab_type":"text"},"source":["- Consider Transforming the predictors inorder to access different statistical methods.\n","- Example, We can transform a categorical variable into ordinal, even if it is not, and see if any intersting results are observed.\n","- We can also convert numerical variables into discrete(i.e, binning); and try them as categorical measures.\n"]},{"cell_type":"markdown","metadata":{"id":"16X4ms11YpDU","colab_type":"text"},"source":["# Examples"]},{"cell_type":"markdown","metadata":{"id":"59ziYUQhYrUs","colab_type":"text"},"source":["## Regression Feature Selection(Numerical Input,Numerical Output)"]},{"cell_type":"markdown","metadata":{"id":"BtcumSprZFoR","colab_type":"text"},"source":["**This is an Example for features selection for regression problem that has numerical input and numerical output.**\n","\n","**We will be using Pearson's Correlation Coefficient via f_regression()**"]},{"cell_type":"code","metadata":{"id":"lzUkoku8Yu0A","colab_type":"code","colab":{}},"source":["from sklearn.datasets import make_regression\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_regression\n","\n","## Generating a Dataset\n","X, y = make_regression(n_samples=100,n_features=10,n_informative=10)\n","\n","## Define Feature Selection\n","fs = SelectKBest(score_func=f_regression,k=8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mpm3QBcHaGn7","colab_type":"code","colab":{}},"source":["X_selected = fs.fit_transform(X,y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hypVUWUSaLBr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"ac77ee94-93fa-42d6-aa70-361fbd09b8b0","executionInfo":{"status":"ok","timestamp":1587787676592,"user_tz":-330,"elapsed":2636,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}}},"source":["print(X_selected.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(100, 8)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lgvcMOJZaoR8","colab_type":"text"},"source":["## Classification Feature Selection(Numerical Input, Categorical Output)"]},{"cell_type":"markdown","metadata":{"id":"pqPfrTTPa0Ef","colab_type":"text"},"source":["**This is an Example for features selection for Classification problem that has numerical input and categorical outputs**\n","\n","**Feature Selection is performed by ANOVA via f_classif()**"]},{"cell_type":"code","metadata":{"id":"QgPXv8SdbIlM","colab_type":"code","colab":{}},"source":["from sklearn.datasets import make_classification\n","from sklearn.feature_selection import f_classif,SelectKBest"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhJU5RXJbYFO","colab_type":"code","colab":{}},"source":["X, y = make_classification(n_samples=100,n_features=20,n_informative=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ytuuIb_bmad","colab_type":"code","colab":{}},"source":["fs = SelectKBest(score_func=f_classif,k=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3qTcNxgbzro","colab_type":"code","colab":{}},"source":["X_selected = fs.fit_transform(X,y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TvwgmXglb37x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"44a31f0b-b1a4-44d2-8d3e-bed7b8996666","executionInfo":{"status":"ok","timestamp":1587787676597,"user_tz":-330,"elapsed":2611,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}}},"source":["print(X_selected.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(100, 5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wQGmU9bRb6CH","colab_type":"text"},"source":["## Recursive Feature Selection"]},{"cell_type":"code","metadata":{"id":"lVsnum2JcfFq","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnR77Pspdv00","colab_type":"code","colab":{}},"source":["adv = pd.read_csv('/content/drive/My Drive/Repos/Git/Statistics-Basics/An Introduction to Statistical Learning/Dataset/Advertising.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjoO7BPOdzJN","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.feature_selection import RFE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQOxWwZ3d_V7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"outputId":"808ddbec-b3f4-4d4d-e66b-759ab76f153c","executionInfo":{"status":"ok","timestamp":1587787676601,"user_tz":-330,"elapsed":2583,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}}},"source":["adv.head(3)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>TV</th>\n","      <th>Radio</th>\n","      <th>Newspaper</th>\n","      <th>Sales</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>230.1</td>\n","      <td>37.8</td>\n","      <td>69.2</td>\n","      <td>22.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>44.5</td>\n","      <td>39.3</td>\n","      <td>45.1</td>\n","      <td>10.4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>17.2</td>\n","      <td>45.9</td>\n","      <td>69.3</td>\n","      <td>9.3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0     TV  Radio  Newspaper  Sales\n","0           1  230.1   37.8       69.2   22.1\n","1           2   44.5   39.3       45.1   10.4\n","2           3   17.2   45.9       69.3    9.3"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"1qGoBDh8eCIp","colab_type":"code","colab":{}},"source":["adv.drop('Unnamed: 0',1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6gwXy6HveNOf","colab_type":"code","colab":{}},"source":["X = adv.drop('Sales',1)\n","y = adv.Sales"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-6CunB_TeWHF","colab_type":"code","colab":{}},"source":["model = LinearRegression()\n","rfe = RFE(estimator=model,n_features_to_select=2)\n","fit = rfe.fit(X,y)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPkIXpeAfuUy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"324caca2-2e65-4e11-f54d-1954532cda72","executionInfo":{"status":"ok","timestamp":1587787676606,"user_tz":-330,"elapsed":2568,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}}},"source":["fit.ranking_"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 2])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"ovGOjzgjgQJE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"672807ca-51a4-4ef2-a311-f6135ebc4f47","executionInfo":{"status":"ok","timestamp":1587787676607,"user_tz":-330,"elapsed":2563,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}}},"source":["X.head()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TV</th>\n","      <th>Radio</th>\n","      <th>Newspaper</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>230.1</td>\n","      <td>37.8</td>\n","      <td>69.2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>44.5</td>\n","      <td>39.3</td>\n","      <td>45.1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>17.2</td>\n","      <td>45.9</td>\n","      <td>69.3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>151.5</td>\n","      <td>41.3</td>\n","      <td>58.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>180.8</td>\n","      <td>10.8</td>\n","      <td>58.4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      TV  Radio  Newspaper\n","0  230.1   37.8       69.2\n","1   44.5   39.3       45.1\n","2   17.2   45.9       69.3\n","3  151.5   41.3       58.5\n","4  180.8   10.8       58.4"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"XyQ7Iq8HgdQw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"837513a9-a972-482e-9151-9bc81a02bb30","executionInfo":{"status":"ok","timestamp":1587787676607,"user_tz":-330,"elapsed":2556,"user":{"displayName":"Shallun Rez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9d2AD0tXMfqM-orZBoybtWPXFojoKbvot04A9=s64","userId":"07939240584398821871"}}},"source":["fit.support_"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ True,  True, False])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"YCOkrOwvgSvx","colab_type":"text"},"source":["**Observation:**\n","- Its seen that the first 2 predictors are selected our of the 3 predictors.\n","- The TV and Radio are the 2 features."]},{"cell_type":"code","metadata":{"id":"zLfAg0Y2g-qN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}