{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Feature Selection Techniques.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMyIIW2QdZ0IGWzdbt5E6Bt"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AY6p61Tqj83Q","colab_type":"text"},"source":["# Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"G4oN6_bqkMlc","colab_type":"text"},"source":["**What is Feature Selection and its uses?**\n","- Feature selection is one of the core concepts in machine learning, which hugely impacts the performance of a model.\n","- The data features that we use to train your machine learning models have a huge influence on the performance that we can achive.\n","- Irrelavant or partially relevant features can negatively impact the model.\n","- Feature selection and Data cleaning is one of the most important steps in model designing.\n"]},{"cell_type":"markdown","metadata":{"id":"5jZnFv5Zlfzq","colab_type":"text"},"source":["**Benefits of Feature Selection:**\n","- Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n","- Improves Accuracy: Less misleading data means model accuracy improvse.\n","- Reduces Training time: Less data means algorithm train faster."]},{"cell_type":"markdown","metadata":{"id":"9MAoao7dl-RD","colab_type":"text"},"source":["**Types of Features Selection algorithms:**\n","- There are two main types of Feature Selection Algorithms.\n","  - Wrapper Feature Selection Methods.\n","  - Filter Feature Selection Methods.\n","  "]},{"cell_type":"markdown","metadata":{"id":"8zQB_itFnkUl","colab_type":"text"},"source":["# Wrapper Feature Selection Methods"]},{"cell_type":"markdown","metadata":{"id":"Kk7PgLZQnok8","colab_type":"text"},"source":["**What is meant by Wrapper Feature Selection?**\n","- It creates many models, with different subset of input features and select those features that result in best performing model according to a performance metric.\n","- These methods are unconcerned about the variable types, although they can be computationally expensive.\n","- **Recursive Feature Elimination(RFE)** is a good example of wrapper feature selection method.\n","\n","***Definition:***\n","- *Wrapper methods evaluvate multiple models using procedures that add/or remove predictors to find the optimal combination that maximizes the model performance.*"]},{"cell_type":"markdown","metadata":{"id":"RTUm8u16o26t","colab_type":"text"},"source":["# Filter Feature Selection Methods"]},{"cell_type":"markdown","metadata":{"id":"VvyKTAizo7WT","colab_type":"text"},"source":["**What is meant by Filter Feature Selection?**\n","- Filter Features Selection uses statistical techniques to evaluvate the relationship between each predictor and the response variable and these scores are used as a basis to choose(filter) those predictors that can be used in your model.\n","\n","**Definition:**\n","- *Filter methods evaluvate the relevance of the predictors outside the predictive models and subsequently model only the predictors that pass some criterion*\n","\n","**Application of Filter Feature Selection:**\n","- It is common to use correlation type statistical measures between input and output variables as a basis for Filter Feature Selection.\n","- As such the choice of statistical measure is highly dependant upon the variable or predictor data types.\n","- Common datatype include both quantitative and qualitative although it may subdivide such as integer and floating point in quantitative and boolean, ordinal or nominal in qualitative predictors.\n","- Common input predictor datatypes:\n","  - Quantitative Predictors.\n","    - Integer Variables\n","    - Floating Point Varaibles\n","  - Qualitative Predictors.\n","    - Boolean Variables(dichotomos)\n","    - Ordinal Variables\n","    - Nominal Varaibles"]},{"cell_type":"markdown","metadata":{"id":"7EGCG-workX3","colab_type":"text"},"source":["## Statistics for Filter based Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"5ZHPHcwwtzrn","colab_type":"text"},"source":["- There are two main groups of variables to consider are : predictors and response variables.\n","- Predictors are the input variables. These are the variables that we wish to reduce in size\n","- Response variable are the output variables, which the model is intended to predict.\n","- The type of response variable  typically indicates the type of predictive modelling problem being performed.\n","  - Numerical Output: Regression predictive modelling problem.\n","  - Categorical Output: Classification predictive modellig problem.\n","- Statistical Measures used in Filter Feature Selection are generally calculated one input variable at a time with the response variable.These are reffered to as the univariate statistical measures."]},{"cell_type":"markdown","metadata":{"id":"bni8AeAxvXyz","colab_type":"text"},"source":["$\\text{Input Features}\\rightarrow\\begin{cases}\n","\\text{Numerical Features}\\rightarrow\\text{Output Variable}\n","\\begin{cases}\n","\\text{Numerical}\\begin{cases}\n","\\text{Pearson's}\\\\\n","\\text{Spearman's}\n","\\end{cases}\\\\\n","\\text{Categorical}\\begin{cases}\n","\\text{ANOVA}\\\\\n","\\text{Kendall's}\n","\\end{cases}\n","\\end{cases}\\\\\n","\\text{Categorical Features}\\rightarrow\\text{Output Variable}\\begin{cases}\n","\\text{Numerical}\\begin{cases}\n","\\text{ANOVA}\\\\\n","\\text{Kendall's}\n","\\end{cases}\\\\\n","\\text{Categorical}\\begin{cases}\n","\\text{Chi-Squared}\\\\\n","\\text{Mutual Information}\n","\\end{cases}\n","\\end{cases}\n","\\end{cases}$"]},{"cell_type":"code","metadata":{"id":"WCVxFdCBxE3l","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}